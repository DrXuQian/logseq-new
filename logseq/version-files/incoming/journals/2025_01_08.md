- [[CUDA kernel]]
	- ## Relu
		- ```c++
		  // Relu x: N, y: N y=max(0,x)
		  // grid(N/128), block(K=128) 
		  __global__ void relu(float* x, float* y, int N) {
		    int idx = blockIdx.x * blockDim.x + threadIdx.x;
		    if (idx < N) y[idx] = fmaxf(0.0f, x[idx]);
		  }
		  
		  // Relu x: N, y: N y=max(0,x) Vec4
		  // grid(N/128/4), block(128/4) 
		  __global__ void relu_vec4(float* x, float* y, int N) {
		    int idx = (blockIdx.x * blockDim.x + threadIdx.x) * 4;
		    if (idx < N) {
		      float4 reg_x = FLOAT4(x[idx]);
		      float4 reg_y;
		      reg_y.x = fmaxf(0.0f, reg_x.x);
		      reg_y.y = fmaxf(0.0f, reg_x.y);
		      reg_y.z = fmaxf(0.0f, reg_x.z);
		      reg_y.w = fmaxf(0.0f, reg_x.w);
		      FLOAT4(y[idx]) = reg_y;
		    }
		  }
		  ```
- # Lecture 8: CUDA Performance Checklist
	- LATER  Read https://arxiv.org/pdf/1804.06826
	  SCHEDULED: <2025-01-10 Fri>
	- ![Lecture 8_ CUDA Performance.pdf](../assets/Lecture_8_CUDA_Performance_1736387875417_0.pdf)
	- ## Performance checklist
		- Coalesced Global Memory Access
			- [[Memory Coalescing]]
		- Maximize occupancy
			- 硬件占用率指 GPU 的计算资源（如寄存器、共享内存、线程）被充分利用的程度。更高的占用率通常意味着更高的吞吐量。
		- Understand if memory or compute bound
			- [[compute bound vs dma bound]]
		- Minimize control divergence
			- [[warp divergence]]
		- [[Tiling of reused data]]
			- [[matrix multiplication]]
		- [[Privatization]]
		- [[Thread Coarsening]]
		- *Rewrite your algorithm using better math*
	- ## Memory latencies
		- https://arxiv.org/abs/2208.11174
		- ![image.png](../assets/image_1736395429067_0.png)
	-
	- ## It’s the latency stupid