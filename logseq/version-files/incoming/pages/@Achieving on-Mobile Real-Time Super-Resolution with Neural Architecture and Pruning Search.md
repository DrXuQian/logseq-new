tags:: [[Computer Science - Computer Vision and Pattern Recognition]], [[Computer Science - Machine Learning]], [[Computer Science - Neural and Evolutionary Computing]], [[Electrical Engineering and Systems Science - Image and Video Processing]]
date:: [[Aug 18th, 2021]]
extra:: arXiv: 2108.08910
title:: @Achieving on-Mobile Real-Time Super-Resolution with Neural Architecture and Pruning Search
item-type:: [[journalArticle]]
access-date:: 2022-02-09T04:25:18Z
original-title:: Achieving on-Mobile Real-Time Super-Resolution with Neural Architecture and Pruning Search
url:: http://arxiv.org/abs/2108.08910
publication-title:: "arXiv:2108.08910 [cs, eess]"
authors:: [[Zheng Zhan]], [[Yifan Gong]], [[Pu Zhao]], [[Geng Yuan]], [[Wei Niu]], [[Yushu Wu]], [[Tianyun Zhang]], [[Malith Jayaweera]], [[David Kaeli]], [[Bin Ren]], [[Xue Lin]], [[Yanzhi Wang]]
library-catalog:: arXiv.org
links:: [Local library](zotero://select/library/items/2K9P8BEV), [Web library](https://www.zotero.org/users/9063164/items/2K9P8BEV)

- [[Abstract]]
	- Though recent years have witnessed remarkable progress in single image super-resolution (SISR) tasks with the prosperous development of deep neural networks (DNNs), the deep learning methods are confronted with the computation and memory consumption issues in practice, especially for resource-limited platforms such as mobile devices. To overcome the challenge and facilitate the real-time deployment of SISR tasks on mobile, we combine neural architecture search with pruning search and propose an automatic search framework that derives sparse super-resolution (SR) models with high image quality while satisfying the real-time inference requirement. To decrease the search cost, we leverage the weight sharing strategy by introducing a supernet and decouple the search problem into three stages, including supernet construction, compiler-aware architecture and pruning search, and compiler-aware pruning ratio search. With the proposed framework, we are the first to achieve real-time SR inference (with only tens of milliseconds per frame) for implementing 720p resolution with competitive image quality (in terms of PSNR and SSIM) on mobile platforms (Samsung Galaxy S20).
- [[Attachments]]
	- [arXiv.org Snapshot](https://arxiv.org/abs/2108.08910) {{zotero-imported-file 2TYARGBB, "2108.html"}}
	- [arXiv Fulltext PDF](https://arxiv.org/pdf/2108.08910.pdf) {{zotero-imported-file WDP3NP4L, "Zhan et al. - 2021 - Achieving on-Mobile Real-Time Super-Resolution wit.pdf"}}
- tags:: [[Computer Science - Computer Vision and Pattern Recognition]], [[Computer Science - Machine Learning]], [[Computer Science - Neural and Evolutionary Computing]], [[Electrical Engineering and Systems Science - Image and Video Processing]]
  date:: [[Aug 18th, 2021]]
  extra:: arXiv: 2108.08910
  title:: @Achieving on-Mobile Real-Time Super-Resolution with Neural Architecture and Pruning Search
  item-type:: [[journalArticle]]
  access-date:: 2022-02-09T04:25:18Z
  original-title:: Achieving on-Mobile Real-Time Super-Resolution with Neural Architecture and Pruning Search
  url:: http://arxiv.org/abs/2108.08910
  publication-title:: "arXiv:2108.08910 [cs, eess]"
  authors:: [[Zheng Zhan]], [[Yifan Gong]], [[Pu Zhao]], [[Geng Yuan]], [[Wei Niu]], [[Yushu Wu]], [[Tianyun Zhang]], [[Malith Jayaweera]], [[David Kaeli]], [[Bin Ren]], [[Xue Lin]], [[Yanzhi Wang]]
  library-catalog:: arXiv.org
  links:: [Local library](zotero://select/library/items/2K9P8BEV), [Web library](https://www.zotero.org/users/9063164/items/2K9P8BEV)
- [[Abstract]]
	- Though recent years have witnessed remarkable progress in single image super-resolution (SISR) tasks with the prosperous development of deep neural networks (DNNs), the deep learning methods are confronted with the computation and memory consumption issues in practice, especially for resource-limited platforms such as mobile devices. To overcome the challenge and facilitate the real-time deployment of SISR tasks on mobile, we combine neural architecture search with pruning search and propose an automatic search framework that derives sparse super-resolution (SR) models with high image quality while satisfying the real-time inference requirement. To decrease the search cost, we leverage the weight sharing strategy by introducing a supernet and decouple the search problem into three stages, including supernet construction, compiler-aware architecture and pruning search, and compiler-aware pruning ratio search. With the proposed framework, we are the first to achieve real-time SR inference (with only tens of milliseconds per frame) for implementing 720p resolution with competitive image quality (in terms of PSNR and SSIM) on mobile platforms (Samsung Galaxy S20).
- [[Attachments]]
	- [arXiv.org Snapshot](https://arxiv.org/abs/2108.08910) {{zotero-imported-file 2TYARGBB, "2108.html"}}
	- [arXiv Fulltext PDF](https://arxiv.org/pdf/2108.08910.pdf) {{zotero-imported-file WDP3NP4L, "Zhan et al. - 2021 - Achieving on-Mobile Real-Time Super-Resolution wit.pdf"}}