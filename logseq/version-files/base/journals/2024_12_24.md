- DONE complete the resume in huawei
  SCHEDULED: <2025-01-07 Tue>
  :LOGBOOK:
  CLOCK: [2024-12-24 Tue 15:47:48]
  CLOCK: [2024-12-24 Tue 15:47:52]
  CLOCK: [2024-12-24 Tue 15:47:57]
  :END:
	- inference optimization by compressing kvcache
		- [[Huawei]]
- ### **[[Dec 30th, 2024]]**
	- DONE CUDA 理论学习：学习 CUDA 线程模型（Threads、Blocks、Grids）。
	- DONE CUDA 实践任务：编写第一个 CUDA Kernel，设置线程布局并运行简单的向量加法（Vector Addition）。
	- DONE C++ 理论学习：学习 C++ 的基础语法（变量、数据类型、输入输出，参考 w3schools）。
	- DONE C++ 实践任务：编写简单的控制台程序，练习变量声明、基本运算和输入输出。
	  
	  ---
- ### **[[Dec 31st, 2024]]**
	- DONE C++ 理论学习：学习 C++ 的循环与条件语句（for、while、if、switch，参考 w3schools）。
	- DONE C++ 实践任务：编写程序实现用户输入数字并判断奇偶，使用循环计算阶乘。
	  
	  ---
- DONE Lecture 2 of GPU mode
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:15:33]
  :END:
- DONE Lecture 3,4,5 of GPU mode
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:15:37]
  CLOCK: [2025-01-01 Wed 20:15:42]
  CLOCK: [2025-01-01 Wed 20:16:23]
  :END:
- DONE Lecture 6,7,8 of GPU mode
  SCHEDULED: <2025-01-08 Wed>
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:17:33]
  :END:
- DONE Write relu, relu + vec4 kernel
  SCHEDULED: <2025-01-08 Wed>
- TODO Write warp/block reduce sum/max, block all reduce + vec4
  SCHEDULED: <2025-01-12 Sun>
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:17:18]
  :END:
- TODO Lecture 9,10,11 of GPU mode
  SCHEDULED: <2025-01-12 Sun>
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:17:57]
  :END:
- TODO Write sigmoid, sigmoid + vec4
  SCHEDULED: <2025-01-12 Sun>
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:18:32]
  :END:
- TODO Write sgemv k32/k128/k16 kernel
  SCHEDULED: <2025-01-13 Mon>
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:18:52]
  :END:
- TODO Write sgemm naive, sgemm + block-tile + k-tile + vec4
  SCHEDULED: <2025-01-13 Mon>
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:19:17]
  :END:
- TODO Lecture 12 of GPU mode
  SCHEDULED: <2025-01-14 Tue>
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:19:29]
  :END:
- TODO flash attention naive
  SCHEDULED: <2025-01-14 Tue>
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:19:49]
  :END:
- TODO Lecture 13,14 of GPU mode
  SCHEDULED: <2025-01-15 Wed>
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:20:03]
  :END:
- TODO flash attention v1/v2/v3 step by step
  SCHEDULED: <2025-01-15 Wed>
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:21:45]
  :END:
- TODO Lecture 15,16,17 of GPU mode
  SCHEDULED: <2025-01-16 Thu>
  :LOGBOOK:
  CLOCK: [2025-01-07 Tue 15:46:26]
  CLOCK: [2025-01-07 Tue 15:47:03]
  :END:
- TODO Ring attention
  SCHEDULED: <2025-01-16 Thu>
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:22:00]
  :END:
- TODO Lecture 18, 19, 20, 21 of GPU mode
  SCHEDULED: <2025-01-17 Fri>
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:21:01]
  :END:
- TODO Page attention kernels
  SCHEDULED: <2025-01-17 Fri>
- TODO Lecture 22, 23 of GPU mode
  SCHEDULED: <2025-01-18 Sat>
- TODO Write code that calls tensor core
  SCHEDULED: <2025-01-18 Sat>
  :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:21:15]
  :END:
- :LOGBOOK:
  CLOCK: [2025-01-01 Wed 20:21:33]
  CLOCK: [2025-01-01 Wed 20:21:41]
  :END:
-