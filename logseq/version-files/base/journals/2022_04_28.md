- [[DPU -> CMX interface]]
	- How can we calculate the utilization of DPU when NTHW, NTK constraint is not met? (activations and weights are not reused enough)
		- But simply we can do a BW calculation to see if we are BW bound or compute bound. The interface is 128B/c to CMX on MTL but actually 256B/c on LNL. So in addition to the tiling efficiency a BW bound vs compute BW calculation needs to be done between the DPU and CMX.
	- For LNL VPU4.0, the DPU interface is 256B/C to CMX. For VPU2.7, the DPU interface is 128B/C to CMX.
	- For LNL, DPU->CMX BW was doubled on LNL as compared to MTL, DPU -> CMX only runs at the lower clock frequency which is a 7:4 ratio. MTL is 4:3 ratio.
	- For small workloads there is some overhead. So avoid small workloads.
		- If we don't consider overlap of multiple layers based on a simulation from the HW team the total latency for a WL that took 16 cycles was ~850 cycles
		  But if there are back to back workloads most of that is hidden, and maybe it is 100 cycles or less, so we need to somehow model that fact - maybe this is a feature we need somehow from the cost model
	- For LNL:
		- every cube (4x4x32 * 16x32x1x1 -> 4x4x16), costs 4 cycles to finish (32/8)
		- So, the total cycle is NTHW * NTK * 4, the data transfer cycle is (NTHW + NTK) * 2 (double for MTL)
		- To avoid Memory bound:
			- For LNL:
				- $$NTHW*NTK*4/fclk>=(NTHW+NTK)*2/fclk*7/4$$
				- $$NTHW*NTK>=(NTHW+NTK)*7/8$$
			- For MTL:
				- $$NTHW*NTK*4/fclk>=(NTHW+NTK)*4/fclk*4/3$$
				- $$NTHW*NTK>=(NTHW+NTK)*4/3$$
			- For VPU5:
				- $$NTHW*NTK*4*4*16*32/2048/dpu\_fclk>=(NTHW+NTK)*512/256/dma\_fclk$$
				- $$NTHW*NTK>=(NTHW+NTK)$$
				- $$(NTHW+NTK)*512/256/dma\_fclk=2(NTHW+NTK)/dma\_fclk$$
				- $$NTHW*NTK*4*4*16*32/2048/dpu\_fclk=4(NTHW*NTK)/dma\_fclk$$
	- For LNL, to make sure it is compute bound:
		- Previously, we assumed Input 4x4x32, weight 16x32x1x1 --> output 4x4x16 would not be BW bound by CMX. So, as the clock frequency is 4/7 of the original frequency. We would need more reuse in HW and K dimension. For example, Input 8x4x32, weight 32x32x1x1 --> output 8x4x32, this can make sure the DPU is compute bound since the DMA time is doubled and Compute time increased 4x.
		- NTHW: 2, NTK: 4
	- For MTL, to make sure it is compute bound:
		- NTHW: 2, NTK: 4
		- NTHW:4, NTK: 2
- [[VPUNN training data]]