- Learn the way Bert works
	 - tokenizer, word embedding
	 - [[Attention]]
	 - training loss function
	 - transfer learning
- Think about how should we organize the website for cg ramp up
- Ideas of IDF
	 - pad to 16, why not pad the other input channels of the kernel to the end