tags:: [[Computer Science - Computer Vision and Pattern Recognition]]
date:: [[May 24th, 2019]]
extra:: arXiv: 1812.03443
title:: @FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search
item-type:: [[journalArticle]]
access-date:: 2022-02-09T04:23:54Z
original-title:: FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search
url:: http://arxiv.org/abs/1812.03443
short-title:: FBNet
publication-title:: arXiv:1812.03443 [cs]
authors:: [[Bichen Wu]], [[Xiaoliang Dai]], [[Peizhao Zhang]], [[Yanghan Wang]], [[Fei Sun]], [[Yiming Wu]], [[Yuandong Tian]], [[Peter Vajda]], [[Yangqing Jia]], [[Kurt Keutzer]]
library-catalog:: arXiv.org
links:: [Local library](zotero://select/library/items/6V587RL5), [Web library](https://www.zotero.org/users/9063164/items/6V587RL5)
- [[Abstract]]
	- Designing accurate and efficient ConvNets for mobile devices is challenging because the design space is combinatorially large. Due to this, previous neural architecture search (NAS) methods are computationally expensive. ConvNet architecture optimality depends on factors such as input resolution and target devices. However, existing approaches are too expensive for case-by-case redesigns. Also, previous work focuses primarily on reducing FLOPs, but FLOP count does not always reflect actual latency. To address these, we propose a differentiable neural architecture search (DNAS) framework that uses gradient-based methods to optimize ConvNet architectures, avoiding enumerating and training individual architectures separately as in previous methods. FBNets, a family of models discovered by DNAS surpass state-of-the-art models both designed manually and generated automatically. FBNet-B achieves 74.1% top-1 accuracy on ImageNet with 295M FLOPs and 23.1 ms latency on a Samsung S8 phone, 2.4x smaller and 1.5x faster than MobileNetV2-1.3 with similar accuracy. Despite higher accuracy and lower latency than MnasNet, we estimate FBNet-B's search cost is 420x smaller than MnasNet's, at only 216 GPU-hours. Searched for different resolutions and channel sizes, FBNets achieve 1.5% to 6.4% higher accuracy than MobileNetV2. The smallest FBNet achieves 50.2% accuracy and 2.9 ms latency (345 frames per second) on a Samsung S8. Over a Samsung-optimized FBNet, the iPhone-X-optimized model achieves a 1.4x speedup on an iPhone X.
- [[Attachments]]
	- [arXiv.org Snapshot](https://arxiv.org/abs/1812.03443) {{zotero-imported-file 2WDX9LZA, "1812.html"}}
	- [arXiv Fulltext PDF](https://arxiv.org/pdf/1812.03443.pdf) {{zotero-imported-file S7WMR8CV, "Wu et al. - 2019 - FBNet Hardware-Aware Efficient ConvNet Design via.pdf"}}
- tags:: [[Computer Science - Computer Vision and Pattern Recognition]]
  date:: [[May 24th, 2019]]
  extra:: arXiv: 1812.03443
  title:: @FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search
  item-type:: [[journalArticle]]
  access-date:: 2022-02-09T04:23:54Z
  original-title:: FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search
  url:: http://arxiv.org/abs/1812.03443
  short-title:: FBNet
  publication-title:: arXiv:1812.03443 [cs]
  authors:: [[Bichen Wu]], [[Xiaoliang Dai]], [[Peizhao Zhang]], [[Yanghan Wang]], [[Fei Sun]], [[Yiming Wu]], [[Yuandong Tian]], [[Peter Vajda]], [[Yangqing Jia]], [[Kurt Keutzer]]
  library-catalog:: arXiv.org
  links:: [Local library](zotero://select/library/items/6V587RL5), [Web library](https://www.zotero.org/users/9063164/items/6V587RL5)
- [[Abstract]]
	- Designing accurate and efficient ConvNets for mobile devices is challenging because the design space is combinatorially large. Due to this, previous neural architecture search (NAS) methods are computationally expensive. ConvNet architecture optimality depends on factors such as input resolution and target devices. However, existing approaches are too expensive for case-by-case redesigns. Also, previous work focuses primarily on reducing FLOPs, but FLOP count does not always reflect actual latency. To address these, we propose a differentiable neural architecture search (DNAS) framework that uses gradient-based methods to optimize ConvNet architectures, avoiding enumerating and training individual architectures separately as in previous methods. FBNets, a family of models discovered by DNAS surpass state-of-the-art models both designed manually and generated automatically. FBNet-B achieves 74.1% top-1 accuracy on ImageNet with 295M FLOPs and 23.1 ms latency on a Samsung S8 phone, 2.4x smaller and 1.5x faster than MobileNetV2-1.3 with similar accuracy. Despite higher accuracy and lower latency than MnasNet, we estimate FBNet-B's search cost is 420x smaller than MnasNet's, at only 216 GPU-hours. Searched for different resolutions and channel sizes, FBNets achieve 1.5% to 6.4% higher accuracy than MobileNetV2. The smallest FBNet achieves 50.2% accuracy and 2.9 ms latency (345 frames per second) on a Samsung S8. Over a Samsung-optimized FBNet, the iPhone-X-optimized model achieves a 1.4x speedup on an iPhone X.
- [[Attachments]]
	- [arXiv.org Snapshot](https://arxiv.org/abs/1812.03443) {{zotero-imported-file 2WDX9LZA, "1812.html"}}
	- [arXiv Fulltext PDF](https://arxiv.org/pdf/1812.03443.pdf) {{zotero-imported-file S7WMR8CV, "Wu et al. - 2019 - FBNet Hardware-Aware Efficient ConvNet Design via.pdf"}}