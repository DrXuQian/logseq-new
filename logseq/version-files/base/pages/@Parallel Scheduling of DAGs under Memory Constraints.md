tags:: [[Computational modeling]], [[DAG]], [[Data models]], [[Dynamic scheduling]], [[Memory]], [[Memory management]], [[Runtime]], [[Schedules]], [[Scheduling]], [[Task analysis]]
date:: 2018-05
conference-name:: 2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)
proceedings-title:: 2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)
extra:: ISSN: 1530-2075
doi:: 10.1109/IPDPS.2018.00030
title:: @Parallel Scheduling of DAGs under Memory Constraints
pages:: 204-213
item-type:: [[conferencePaper]]
original-title:: Parallel Scheduling of DAGs under Memory Constraints
authors:: [[Loris Marchal]], [[Hanna Nagy]], [[Bertrand Simon]], [[Frédéric Vivien]]
library-catalog:: IEEE Xplore
links:: [Local library](zotero://select/library/items/7ITDC3XT), [Web library](https://www.zotero.org/users/9063164/items/7ITDC3XT)
- [[Abstract]]
	- Scientific workflows are frequently modeled as Directed Acyclic Graphs (DAG) of tasks, which represent computational modules and their dependencies, in the form of data produced by a task and used by another one. This formulation allows the use of runtime systems which dynamically allocate tasks onto the resources of increasingly complex and heterogeneous computing platforms. However, for some workflows, such a dynamic schedule may run out of memory by exposing too much parallelism. This paper focuses on the problem of transforming such a DAG to prevent memory shortage, and concentrates on shared memory platforms. We first propose a simple model of DAG which is expressive enough to emulate complex memory behaviors. We then exhibit a polynomial-time algorithm that computes the maximum memory peak of a DAG, that is, the maximum memory needed by any parallel schedule. We consider the problem of reducing this maximum memory peak to make it smaller than a given bound by adding new fictitious edges, while trying to minimize the critical path of the graph. After proving this problem NP-complete, we provide an ILP solution as well as several heuristic strategies that are thoroughly compared by simulation on both synthetic and actual computation DAGs. We show that on most instances, we are able to decrease the maximum memory peak at the cost of a small increase in the critical path, thus with little impact on quality of the final parallel schedule.
- [[Attachments]]
	- [IEEE Xplore Abstract Record](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8425174) {{zotero-imported-file S57CVKRY, "stamp.html"}}
- tags:: [[Computational modeling]], [[DAG]], [[Data models]], [[Dynamic scheduling]], [[Memory]], [[Memory management]], [[Runtime]], [[Schedules]], [[Scheduling]], [[Task analysis]]
  date:: 2018-05
  conference-name:: 2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)
  proceedings-title:: 2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)
  extra:: ISSN: 1530-2075
  doi:: 10.1109/IPDPS.2018.00030
  title:: @Parallel Scheduling of DAGs under Memory Constraints
  pages:: 204-213
  item-type:: [[conferencePaper]]
  original-title:: Parallel Scheduling of DAGs under Memory Constraints
  authors:: [[Loris Marchal]], [[Hanna Nagy]], [[Bertrand Simon]], [[Frédéric Vivien]]
  library-catalog:: IEEE Xplore
  links:: [Local library](zotero://select/library/items/7ITDC3XT), [Web library](https://www.zotero.org/users/9063164/items/7ITDC3XT)
- [[Abstract]]
	- Scientific workflows are frequently modeled as Directed Acyclic Graphs (DAG) of tasks, which represent computational modules and their dependencies, in the form of data produced by a task and used by another one. This formulation allows the use of runtime systems which dynamically allocate tasks onto the resources of increasingly complex and heterogeneous computing platforms. However, for some workflows, such a dynamic schedule may run out of memory by exposing too much parallelism. This paper focuses on the problem of transforming such a DAG to prevent memory shortage, and concentrates on shared memory platforms. We first propose a simple model of DAG which is expressive enough to emulate complex memory behaviors. We then exhibit a polynomial-time algorithm that computes the maximum memory peak of a DAG, that is, the maximum memory needed by any parallel schedule. We consider the problem of reducing this maximum memory peak to make it smaller than a given bound by adding new fictitious edges, while trying to minimize the critical path of the graph. After proving this problem NP-complete, we provide an ILP solution as well as several heuristic strategies that are thoroughly compared by simulation on both synthetic and actual computation DAGs. We show that on most instances, we are able to decrease the maximum memory peak at the cost of a small increase in the critical path, thus with little impact on quality of the final parallel schedule.
- [[Attachments]]
	- [Submitted Version](https://hal.inria.fr/hal-01828312/file/IPDPS.pdf) {{zotero-imported-file 9VQDJL37, "Marchal et al. - 2018 - Parallel Scheduling of DAGs under Memory Constrain.pdf"}}
	- [IEEE Xplore Abstract Record](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8425174) {{zotero-imported-file S57CVKRY, "stamp.html"}}
- tags:: [[Computational modeling]], [[DAG]], [[Data models]], [[Dynamic scheduling]], [[Memory]], [[Memory management]], [[Runtime]], [[Schedules]], [[Scheduling]], [[Task analysis]]
  date:: 2018-05
  conference-name:: 2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)
  proceedings-title:: 2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)
  extra:: ISSN: 1530-2075
  doi:: 10.1109/IPDPS.2018.00030
  title:: @Parallel Scheduling of DAGs under Memory Constraints
  pages:: 204-213
  item-type:: [[conferencePaper]]
  original-title:: Parallel Scheduling of DAGs under Memory Constraints
  authors:: [[Loris Marchal]], [[Hanna Nagy]], [[Bertrand Simon]], [[Frédéric Vivien]]
  library-catalog:: IEEE Xplore
  links:: [Local library](zotero://select/library/items/7ITDC3XT), [Web library](https://www.zotero.org/users/9063164/items/7ITDC3XT)
- [[Abstract]]
	- Scientific workflows are frequently modeled as Directed Acyclic Graphs (DAG) of tasks, which represent computational modules and their dependencies, in the form of data produced by a task and used by another one. This formulation allows the use of runtime systems which dynamically allocate tasks onto the resources of increasingly complex and heterogeneous computing platforms. However, for some workflows, such a dynamic schedule may run out of memory by exposing too much parallelism. This paper focuses on the problem of transforming such a DAG to prevent memory shortage, and concentrates on shared memory platforms. We first propose a simple model of DAG which is expressive enough to emulate complex memory behaviors. We then exhibit a polynomial-time algorithm that computes the maximum memory peak of a DAG, that is, the maximum memory needed by any parallel schedule. We consider the problem of reducing this maximum memory peak to make it smaller than a given bound by adding new fictitious edges, while trying to minimize the critical path of the graph. After proving this problem NP-complete, we provide an ILP solution as well as several heuristic strategies that are thoroughly compared by simulation on both synthetic and actual computation DAGs. We show that on most instances, we are able to decrease the maximum memory peak at the cost of a small increase in the critical path, thus with little impact on quality of the final parallel schedule.
- [[Attachments]]
	- [Submitted Version](https://hal.inria.fr/hal-01828312/file/IPDPS.pdf) {{zotero-imported-file 9VQDJL37, "Marchal et al. - 2018 - Parallel Scheduling of DAGs under Memory Constrain.pdf"}}
	- [IEEE Xplore Abstract Record](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8425174) {{zotero-imported-file S57CVKRY, "stamp.html"}}