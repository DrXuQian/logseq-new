date:: 2019
publisher:: Springer International Publishing
place:: Cham
isbn:: 978-3-030-11020-8 978-3-030-11021-5
title:: @ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks
book-title:: Computer Vision – ECCV 2018 Workshops
pages:: 63-79
volume:: 11133
item-type:: [[bookSection]]
access-date:: 2022-02-11T03:21:42Z
original-title:: ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks
language:: en
url:: http://link.springer.com/10.1007/978-3-030-11021-5_5
short-title:: ESRGAN
authors:: [[Xintao Wang]], [[Ke Yu]], [[Shixiang Wu]], [[Jinjin Gu]], [[Yihao Liu]], [[Chao Dong]], [[Yu Qiao]], [[Chen Change Loy]]
library-catalog:: DOI.org (Crossref)
links:: [Local library](zotero://select/library/items/6G6ERSTG), [Web library](https://www.zotero.org/users/9063164/items/6G6ERSTG)
- [[Abstract]]
	- The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN – network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Beneﬁting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the ﬁrst place in the PIRM2018-SR Challenge (region 3) with the best perceptual index. The code is available at https://github.com/xinntao/ESRGAN.
- [[Attachments]]
	- [Wang et al. - 2019 - ESRGAN Enhanced Super-Resolution Generative Adver.pdf](https://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Wang_ESRGAN_Enhanced_Super-Resolution_Generative_Adversarial_Networks_ECCVW_2018_paper.pdf) {{zotero-imported-file 3UYVI4IJ, "Wang et al. - 2019 - ESRGAN Enhanced Super-Resolution Generative Adver.pdf"}}
- date:: 2019
  publisher:: Springer International Publishing
  place:: Cham
  isbn:: 978-3-030-11020-8 978-3-030-11021-5
  title:: @ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks
  book-title:: Computer Vision – ECCV 2018 Workshops
  pages:: 63-79
  volume:: 11133
  item-type:: [[bookSection]]
  access-date:: 2022-02-11T03:21:42Z
  original-title:: ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks
  language:: en
  url:: http://link.springer.com/10.1007/978-3-030-11021-5_5
  short-title:: ESRGAN
  authors:: [[Xintao Wang]], [[Ke Yu]], [[Shixiang Wu]], [[Jinjin Gu]], [[Yihao Liu]], [[Chao Dong]], [[Yu Qiao]], [[Chen Change Loy]]
  library-catalog:: DOI.org (Crossref)
  links:: [Local library](zotero://select/library/items/6G6ERSTG), [Web library](https://www.zotero.org/users/9063164/items/6G6ERSTG)
- [[Abstract]]
	- The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN – network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Beneﬁting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the ﬁrst place in the PIRM2018-SR Challenge (region 3) with the best perceptual index. The code is available at https://github.com/xinntao/ESRGAN.
- [[Attachments]]
	- [Wang et al. - 2019 - ESRGAN Enhanced Super-Resolution Generative Adver.pdf](https://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Wang_ESRGAN_Enhanced_Super-Resolution_Generative_Adversarial_Networks_ECCVW_2018_paper.pdf) {{zotero-imported-file 3UYVI4IJ, "Wang et al. - 2019 - ESRGAN Enhanced Super-Resolution Generative Adver.pdf"}}