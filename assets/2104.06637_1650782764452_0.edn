{:highlights [{:id #uuid "6264fa8e-af91-430b-93f1-2f2691650cab", :page 1, :position {:bounding {:x1 83.515625, :y1 639.609375, :x2 477.284912109375, :y2 792.515625, :width 1019.9999999999999, :height 1319.9999999999998}, :rects ({:x1 213.984375, :y1 639.609375, :x2 477.0001220703125, :y2 658.609375, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 83.515625, :y1 658.734375, :x2 477.27093505859375, :y2 677.734375, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 83.515625, :y1 677.875, :x2 477.2716064453125, :y2 696.875, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 83.515625, :y1 697, :x2 477.27734375, :y2 716, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 83.515625, :y1 716.125, :x2 476.9952392578125, :y2 735.125, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 83.515625, :y1 735.25, :x2 477.2830810546875, :y2 754.25, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 83.515625, :y1 754.375, :x2 477.284912109375, :y2 773.375, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 83.515625, :y1 773.515625, :x2 285.58648681640625, :y2 792.515625, :width 1019.9999999999999, :height 1319.9999999999998}), :page 1}, :content {:text "Our  proposed  DSTT  disentangles  thetask of learning spatial-temporal attention into 2 sub-tasks:one is for attending temporal object movements on differ-ent frames at same spatial locations, which is achieved bytemporally-decoupled Transformer block, and the other isfor  attending  similar  background  textures  on  same  frameof  all  spatial  positions,  which  is  achieved  by  spatially-decoupled  Transformer  block."}, :properties {:color "yellow"}} {:id #uuid "62654dbf-36e1-4d79-9f94-c69b147cf7b8", :page 3, :position {:bounding {:x1 617.71875, :y1 1212.40625, :x2 1090.2359619140625, :y2 1353.953125, :width 1224, :height 1584}, :rects ({:x1 641.625, :y1 1212.40625, :x2 1090.23388671875, :y2 1234.40625, :width 1224, :height 1584} {:x1 617.71875, :y1 1236.3125, :x2 1090.2276611328125, :y2 1258.3125, :width 1224, :height 1584} {:x1 617.71875, :y1 1260.234375, :x2 1090.2359619140625, :y2 1282.234375, :width 1224, :height 1584} {:x1 617.71875, :y1 1284.140625, :x2 1041.40625, :y2 1306.140625, :width 1224, :height 1584} {:x1 1066.984375, :y1 1284.140625, :x2 1090.220703125, :y2 1306.140625, :width 1224, :height 1584} {:x1 1041.5625, :y1 1292.015625, :x2 1060.164306640625, :y2 1308.015625, :width 1224, :height 1584} {:x1 617.71875, :y1 1308.046875, :x2 1090.2349853515625, :y2 1330.046875, :width 1224, :height 1584} {:x1 617.71875, :y1 1331.953125, :x2 690.4805297851562, :y2 1353.953125, :width 1224, :height 1584}), :page 3}, :content {:text "The overall framework of our proposed method is illus-trated  in  Fig.  3.   Given  a  corrupted  video  sequence  withits  corresponding  mask  sequence,  individual  frames  arefirst input into a frame-based hierarchical encoderGHEfordownsampling and embedding into spatial-temporal tokenvectors.  "}, :properties {:color "yellow"}} {:id #uuid "6265e866-d2b0-4b2f-b913-29791126d358", :page 5, :position {:bounding {:x1 514.765625, :y1 500.390625, :x2 908.533935546875, :y2 658.859375, :width 1019.9999999999999, :height 1319.9999999999998}, :rects ({:x1 639.3477783203125, :y1 500.390625, :x2 908.5146484375, :y2 519.390625, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 514.765625, :y1 520.3125, :x2 908.51220703125, :y2 539.3125, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 514.765625, :y1 540.234375, :x2 908.533935546875, :y2 559.234375, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 514.765625, :y1 560.171875, :x2 908.5322265625, :y2 579.171875, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 514.765625, :y1 580.09375, :x2 908.244140625, :y2 599.09375, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 514.765625, :y1 600.015625, :x2 907.6820068359375, :y2 619.015625, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 514.765625, :y1 619.9375, :x2 908.52783203125, :y2 638.9375, :width 1019.9999999999999, :height 1319.9999999999998} {:x1 514.765625, :y1 639.859375, :x2 874.322021484375, :y2 658.859375, :width 1019.9999999999999, :height 1319.9999999999998}), :page 5}, :content {:text "Althought= 5is chosen during train-ing,  using a largertduring inference will produce videoswith much better visual quality and temporal consistency.So  the  inference  speed  is  boosted  to  a  great  extent.   Fol-lowing STTN [36], we set the number of all stacked Trans-former blocks to8.   As for the stacking strategy,  we em-pirically make a temporally-decoupled block followed by aspatially-decoupled block and repeat this for4times."}, :properties {:color "yellow"}}]}