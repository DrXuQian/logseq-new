date:: 2018
publisher:: Springer International Publishing
place:: Cham
isbn:: 978-3-030-01233-5 978-3-030-01234-2
title:: @Image Super-Resolution Using Very Deep Residual Channel Attention Networks
book-title:: Computer Vision – ECCV 2018
pages:: 294-310
volume:: 11211
item-type:: [[bookSection]]
access-date:: 2022-02-11T03:21:35Z
original-title:: Image Super-Resolution Using Very Deep Residual Channel Attention Networks
language:: en
url:: http://link.springer.com/10.1007/978-3-030-01234-2_18
authors:: [[Yulun Zhang]], [[Kunpeng Li]], [[Kai Li]], [[Lichen Wang]], [[Bineng Zhong]], [[Yun Fu]]
library-catalog:: DOI.org (Crossref)
links:: [Local library](zotero://select/library/items/YX5A4D4D), [Web library](https://www.zotero.org/users/9063164/items/YX5A4D4D)
- [[Abstract]]
	- Convolutional neural network (CNN) depth is of crucial importance for image super-resolution (SR). However, we observe that deeper networks for image SR are more diﬃcult to train. The lowresolution inputs and features contain abundant low-frequency information, which is treated equally across channels, hence hindering the representational ability of CNNs. To solve these problems, we propose the very deep residual channel attention networks (RCAN). Speciﬁcally, we propose a residual in residual (RIR) structure to form very deep network, which consists of several residual groups with long skip connections. Each residual group contains some residual blocks with short skip connections. Meanwhile, RIR allows abundant low-frequency information to be bypassed through multiple skip connections, making the main network focus on learning high-frequency information. Furthermore, we propose a channel attention mechanism to adaptively rescale channel-wise features by considering interdependencies among channels. Extensive experiments show that our RCAN achieves better accuracy and visual improvements against state-of-the-art methods.
- [[Attachments]]
	- [Zhang et al. - 2018 - Image Super-Resolution Using Very Deep Residual Ch.pdf](https://openaccess.thecvf.com/content_ECCV_2018/papers/Yulun_Zhang_Image_Super-Resolution_Using_ECCV_2018_paper.pdf) {{zotero-imported-file 9WM4T3GQ, "Zhang et al. - 2018 - Image Super-Resolution Using Very Deep Residual Ch.pdf"}}
- date:: 2018
  publisher:: Springer International Publishing
  place:: Cham
  isbn:: 978-3-030-01233-5 978-3-030-01234-2
  title:: @Image Super-Resolution Using Very Deep Residual Channel Attention Networks
  book-title:: Computer Vision – ECCV 2018
  pages:: 294-310
  volume:: 11211
  item-type:: [[bookSection]]
  access-date:: 2022-02-11T03:21:35Z
  original-title:: Image Super-Resolution Using Very Deep Residual Channel Attention Networks
  language:: en
  url:: http://link.springer.com/10.1007/978-3-030-01234-2_18
  authors:: [[Yulun Zhang]], [[Kunpeng Li]], [[Kai Li]], [[Lichen Wang]], [[Bineng Zhong]], [[Yun Fu]]
  library-catalog:: DOI.org (Crossref)
  links:: [Local library](zotero://select/library/items/YX5A4D4D), [Web library](https://www.zotero.org/users/9063164/items/YX5A4D4D)
- [[Abstract]]
	- Convolutional neural network (CNN) depth is of crucial importance for image super-resolution (SR). However, we observe that deeper networks for image SR are more diﬃcult to train. The lowresolution inputs and features contain abundant low-frequency information, which is treated equally across channels, hence hindering the representational ability of CNNs. To solve these problems, we propose the very deep residual channel attention networks (RCAN). Speciﬁcally, we propose a residual in residual (RIR) structure to form very deep network, which consists of several residual groups with long skip connections. Each residual group contains some residual blocks with short skip connections. Meanwhile, RIR allows abundant low-frequency information to be bypassed through multiple skip connections, making the main network focus on learning high-frequency information. Furthermore, we propose a channel attention mechanism to adaptively rescale channel-wise features by considering interdependencies among channels. Extensive experiments show that our RCAN achieves better accuracy and visual improvements against state-of-the-art methods.
- [[Attachments]]
	- [Zhang et al. - 2018 - Image Super-Resolution Using Very Deep Residual Ch.pdf](https://openaccess.thecvf.com/content_ECCV_2018/papers/Yulun_Zhang_Image_Super-Resolution_Using_ECCV_2018_paper.pdf) {{zotero-imported-file 9WM4T3GQ, "Zhang et al. - 2018 - Image Super-Resolution Using Very Deep Residual Ch.pdf"}}